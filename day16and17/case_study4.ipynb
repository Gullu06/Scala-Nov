{"cells":[{"cell_type":"code","execution_count":5,"id":"93ecbb08","metadata":{},"outputs":[{"data":{"text/plain":["lastException = null\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["null"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["import org.apache.spark.{SparkConf, SparkContext}\n","import org.apache.spark.sql.functions._\n","import org.apache.spark.rdd.RDD\n","import scala.util.parsing.json.JSON\n","import org.apache.spark.sql.DataFrame"]},{"cell_type":"code","execution_count":6,"id":"19256d2a","metadata":{},"outputs":[{"data":{"text/plain":["moviePath = gs://priyanshi-spark-bucket-3/movie.csv\n","moviesDF = [movieId: int, title: string ... 1 more field]\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["[movieId: int, title: string ... 1 more field]"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["// Load movies.csv from GCP Cloud Storage as a DataFrame\n","val moviePath = \"gs://priyanshi-spark-bucket-3/movie.csv\"\n","val moviesDF = spark.read\n","    .option(\"header\", \"true\")\n","    .option(\"inferSchema\", \"true\")\n","    .csv(moviePath)\n","    .cache()"]},{"cell_type":"code","execution_count":7,"id":"a078f845","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------+-----+------+-----+\n","|movieId|title|genres|count|\n","+-------+-----+------+-----+\n","+-------+-----+------+-----+\n","\n"]},{"data":{"text/plain":["duplicateMoviesDF = [movieId: int, title: string ... 2 more fields]\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["[movieId: int, title: string ... 2 more fields]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["import org.apache.spark.sql.functions._\n","val duplicateMoviesDF = moviesDF\n","  .groupBy(moviesDF.columns.map(col): _*) // Group by all columns\n","  .count()\n","  .filter($\"count\" > 1) // Keep only duplicates\n","duplicateMoviesDF.show()"]},{"cell_type":"code","execution_count":8,"id":"91d94732","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------+--------------------+--------------------+\n","|movieId|               title|              genres|\n","+-------+--------------------+--------------------+\n","|      1|    Toy Story (1995)|Adventure|Animati...|\n","|      2|      Jumanji (1995)|Adventure|Childre...|\n","|      3|Grumpier Old Men ...|      Comedy|Romance|\n","|      4|Waiting to Exhale...|Comedy|Drama|Romance|\n","|      5|Father of the Bri...|              Comedy|\n","|      6|         Heat (1995)|Action|Crime|Thri...|\n","|      7|      Sabrina (1995)|      Comedy|Romance|\n","|      8| Tom and Huck (1995)|  Adventure|Children|\n","|      9| Sudden Death (1995)|              Action|\n","|     10|    GoldenEye (1995)|Action|Adventure|...|\n","|     11|American Presiden...|Comedy|Drama|Romance|\n","|     12|Dracula: Dead and...|       Comedy|Horror|\n","|     13|        Balto (1995)|Adventure|Animati...|\n","|     14|        Nixon (1995)|               Drama|\n","|     15|Cutthroat Island ...|Action|Adventure|...|\n","|     16|       Casino (1995)|         Crime|Drama|\n","|     17|Sense and Sensibi...|       Drama|Romance|\n","|     18|   Four Rooms (1995)|              Comedy|\n","|     19|Ace Ventura: When...|              Comedy|\n","|     20|  Money Train (1995)|Action|Comedy|Cri...|\n","+-------+--------------------+--------------------+\n","only showing top 20 rows\n","\n"]},{"data":{"text/plain":["schema = StructType(StructField(movieId,IntegerType,true),StructField(title,StringType,true),StructField(genres,StringType,true))\n","duplicateRows = List([1,Toy Story (1995),Adventure|Animation|Children|Comedy], [2,Jumanji (1995),Adventure|Children|Fantasy], [7,Sabrina (1995),Comedy|Romance], [13,Nixon (1995),Drama])\n","duplicateDF = [movieId: int, title: string ... 1 more field]\n","moviesWithDuplicatesDF = [movieId: int, title: string ... 1 more field]\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["[movieId: int, title: string ... 1 more field]"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["import org.apache.spark.sql.Row\n","import org.apache.spark.sql.types._\n","// Define a schema for the movies\n","val schema = moviesDF.schema\n","// Create duplicate rows manually\n","val duplicateRows = Seq(\n","  Row(1, \"Toy Story (1995)\", \"Adventure|Animation|Children|Comedy\"),\n","  Row(2, \"Jumanji (1995)\", \"Adventure|Children|Fantasy\"),\n","    Row(7, \"Sabrina (1995)\", \"Comedy|Romance\"),\n","    Row(13, \"Nixon (1995)\", \"Drama\")\n",")\n","// Convert duplicate rows to a DataFrame\n","val duplicateDF = spark.createDataFrame(\n","  spark.sparkContext.parallelize(duplicateRows),\n","  schema\n",")\n","// Union the original DataFrame with the duplicate DataFrame\n","val moviesWithDuplicatesDF = moviesDF.union(duplicateDF)\n","moviesWithDuplicatesDF.show()"]},{"cell_type":"code","execution_count":9,"id":"938e10f2","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------+----------------+-----+\n","|movieId|           title|count|\n","+-------+----------------+-----+\n","|      2|  Jumanji (1995)|    2|\n","|      1|Toy Story (1995)|    2|\n","|      7|  Sabrina (1995)|    2|\n","+-------+----------------+-----+\n","\n"]},{"data":{"text/plain":["duplicatesDF = [movieId: int, title: string ... 1 more field]\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["[movieId: int, title: string ... 1 more field]"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["import org.apache.spark.sql.functions._\n","val duplicatesDF = moviesWithDuplicatesDF\n","  .groupBy(\"movieId\", \"title\") // Group by movieId and title\n","  .count()                     // Count occurrences\n","  .filter($\"count\" > 1)        // Filter rows where count > 1\n","duplicatesDF.show()"]},{"cell_type":"code","execution_count":10,"id":"74cd71f8","metadata":{},"outputs":[{"data":{"text/plain":["duplicateMoviesDF = [movieId: int, title: string ... 1 more field]\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["[movieId: int, title: string ... 1 more field]"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["val duplicateMoviesDF = moviesDF.union(duplicatesDF)\n","duplicateMoviesDF.write\n","  .option(\"header\", \"true\")\n","  .mode(\"overwrite\") // Overwrite the existing file\n","  .csv(\"hdfs:///user/priyanshi-spark-bucket-3/duplicated_movie.csv\")"]},{"cell_type":"code","execution_count":11,"id":"7257aa64","metadata":{},"outputs":[{"data":{"text/plain":["moviesPath = hdfs:///user/priyanshi-spark-bucket-3/duplicated_movie.csv\n","moviesDF = [movieId: string, title: string ... 1 more field]\n","cleanedMoviesDF = [movieId: string, title: string ... 1 more field]\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["[movieId: string, title: string ... 1 more field]"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["val moviesPath = \"hdfs:///user/priyanshi-spark-bucket-3/duplicated_movie.csv\"\n","val moviesDF = spark.read.option(\"header\", \"true\").csv(moviesPath)\n","//Convert to RDD with composite key (movieId, title) and Remove duplicate records\n","val cleanedMoviesDF = moviesDF.rdd.map(row => {\n","  val movieId = row.getString(row.fieldIndex(\"movieId\"))\n","  val title = row.getString(row.fieldIndex(\"title\"))\n","  val genres = row.getString(row.fieldIndex(\"genres\"))\n","  ((movieId, title), genres) // Key: (movieId, title), Value: genres\n","}).reduceByKey((genres1, genres2) => s\"$genres1|$genres2\").map {\n","  case ((movieId, title), combinedGenres) => (movieId, title, combinedGenres)\n","}.toDF(\"movieId\", \"title\", \"genres\")"]},{"cell_type":"code","execution_count":12,"id":"01017383","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Original record count: 27281\n","Deduplicated record count: 27278\n","Duplicates removed: 3\n"]},{"data":{"text/plain":["originalCount = 27281\n","deduplicatedCount = 27278\n","duplicatesRemoved = 3\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["3"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["// // Step 4: Validation\n","val originalCount = moviesDF.count()\n","val deduplicatedCount = cleanedMoviesDF.count()\n","val duplicatesRemoved = originalCount - deduplicatedCount\n","println(s\"Original record count: $originalCount\")\n","println(s\"Deduplicated record count: $deduplicatedCount\")\n","println(s\"Duplicates removed: $duplicatesRemoved\")"]},{"cell_type":"code","execution_count":13,"id":"4600294a","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Marking org.apache.spark:spark-avro_2.12:3.3.2 for download\n","Obtained 12 files\n","Marking org.apache.spark:spark-avro_2.12:3.3.2 for download\n","Obtained 12 files\n"]}],"source":["%AddDeps org.apache.spark spark-avro_2.12 3.3.2 --transitive"]},{"cell_type":"code","execution_count":14,"id":"e6b60e09","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Cleaned movies data saved successfully in Avro format.\n"]},{"data":{"text/plain":["outputPath = gs://priyanshi-spark-bucket-3/cleaned_movies.avro\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["gs://priyanshi-spark-bucket-3/cleaned_movies.avro"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["val outputPath = s\"gs://priyanshi-spark-bucket-3/cleaned_movies.avro\"\n","cleanedMoviesDF.write\n","  .format(\"avro\")\n","  .mode(\"overwrite\")\n","  .save(outputPath)\n","println(\"Cleaned movies data saved successfully in Avro format.\")"]},{"cell_type":"code","execution_count":null,"id":"7d42a979","metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Apache Toree - Scala","language":"scala","name":"apache_toree_scala"},"language_info":{"codemirror_mode":"text/x-scala","file_extension":".scala","mimetype":"text/x-scala","name":"scala","pygments_lexer":"scala","version":"2.12.15"}},"nbformat":4,"nbformat_minor":5}